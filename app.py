import streamlit as st
import torch
import numpy as np
from PIL import Image
from torchvision import transforms
from skimage.color import rgb2lab, lab2rgb
import os

# --- IMPORT MODEL ---
# ƒê·∫£m b·∫£o b·∫°n c√≥ file model.py ch·ª©a class UnetColor c√πng th∆∞ m·ª•c
from model import UnetColor

# --- C·∫§U H√åNH ---
MODEL_PATH = "colorization_model.pth"
IMG_SIZE = 256

# --- C·∫§U H√åNH TRANG WEB ---
st.set_page_config(
    page_title="AI Colorizer Pro",
    page_icon="üé®",
    layout="wide"
)

st.title("üé® AI Image Colorization (Full Resolution)")

# --- LOAD MODEL ---
@st.cache_resource
def load_model():
    # T·ª± ƒë·ªông ch·ªçn GPU n·∫øu c√≥, kh√¥ng th√¨ d√πng CPU
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model = UnetColor().to(device)
    
    if not os.path.exists(MODEL_PATH):
        return None, device
        
    try:
        # Load weights
        checkpoint = torch.load(MODEL_PATH, map_location=device)
        model.load_state_dict(checkpoint)
        model.eval()
        return model, device
    except Exception as e:
        st.error(f"L·ªói khi load model: {e}")
        return None, device

# G·ªçi h√†m load
model, device = load_model()

# Ki·ªÉm tra tr·∫°ng th√°i model
if model is None:
    st.error(f"‚ùå Kh√¥ng t√¨m th·∫•y file '{MODEL_PATH}' ho·∫∑c file b·ªã l·ªói.")
    st.info("üëâ H√£y t·∫£i file .pth t·ª´ Colab v·ªÅ v√† ƒë·∫∑t v√†o c√πng th∆∞ m·ª•c v·ªõi app.py")
else:
    st.sidebar.success(f"‚úÖ System Ready! Device: {device}")

# --- GIAO DI·ªÜN UPLOAD ---
uploaded_file = st.file_uploader("Ch·ªçn ·∫£nh ƒëen tr·∫Øng (ho·∫∑c ·∫£nh m√†u) ƒë·ªÉ test...", type=["jpg", "jpeg", "png"])

if uploaded_file is not None:
    # 1. ƒê·ªçc ·∫£nh v√† chuy·ªÉn v·ªÅ RGB
    image = Image.open(uploaded_file).convert("RGB")
    
    # L·∫•y k√≠ch th∆∞·ªõc g·ªëc (Width, Height) ƒë·ªÉ l√°t n·ªØa ph√≥ng to l·∫°i
    orig_w, orig_h = image.size
    
    # Chia c·ªôt giao di·ªán
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("üì∏ ·∫¢nh g·ªëc")
        st.image(image.convert("L"), use_container_width=True)

    # N√∫t b·∫•m x·ª≠ l√Ω
    if st.button("üöÄ T√¥ m√†u ngay", use_container_width=True):
        with st.spinner("AI ƒëang t√¥ m√†u... vui l√≤ng ƒë·ª£i..."):
            try:
                # --- GIAI ƒêO·∫†N 1: X·ª¨ L√ù ·∫¢NH G·ªêC (L·∫§Y N√âT) ---
                # Chuy·ªÉn ·∫£nh g·ªëc sang m·∫£ng Numpy
                img_original_np = np.array(image)
                # Chuy·ªÉn sang kh√¥ng gian Lab
                img_lab_original = rgb2lab(img_original_np).astype("float32")
                # T√°ch l·∫•y l·ªõp L (Lightness) ·ªü ƒë·ªô ph√¢n gi·∫£i g·ªëc -> D√πng c√°i n√†y ƒë·ªÉ ·∫£nh n√©t
                L_original = img_lab_original[:, :, 0] 

                # --- GIAI ƒêO·∫†N 2: CHU·∫®N B·ªä INPUT CHO AI (RESIZE) ---
                # AI ch·ªâ nh·∫≠n ·∫£nh vu√¥ng 256x256, n√™n ph·∫£i resize m·ªôt b·∫£n copy
                transform = transforms.Compose([
                    transforms.Resize((IMG_SIZE, IMG_SIZE), interpolation=transforms.InterpolationMode.BICUBIC),
                ])
                img_resized = transform(image)
                img_array_resized = np.array(img_resized)
                
                # Chuy·ªÉn b·∫£n resize sang Lab ƒë·ªÉ l·∫•y ƒë·∫ßu v√†o cho Model
                img_lab_resized = rgb2lab(img_array_resized).astype("float32")
                L_input = img_lab_resized[:, :, 0]
                
                # Chu·∫©n h√≥a v·ªÅ kho·∫£ng [-1, 1] v√† t·∫°o Tensor
                L_tensor = torch.from_numpy(L_input).unsqueeze(0).unsqueeze(0) # (1, 1, 256, 256)
                L_tensor = L_tensor / 50. - 1.
                L_tensor = L_tensor.to(device)
                
                # --- GIAI ƒêO·∫†N 3: AI D·ª∞ ƒêO√ÅN M√ÄU ---
                with torch.no_grad():
                    ab_pred = model(L_tensor) # K·∫øt qu·∫£ ra size (1, 2, 256, 256)

                # --- GIAI ƒêO·∫†N 4: H·∫¨U X·ª¨ L√ù (QUAN TR·ªåNG) ---
                # Ph√≥ng to l·ªõp m√†u ab t·ª´ 256x256 l√™n k√≠ch th∆∞·ªõc g·ªëc (orig_h, orig_w)
                ab_pred_upscaled = torch.nn.functional.interpolate(
                    ab_pred, 
                    size=(orig_h, orig_w), 
                    mode='bilinear', 
                    align_corners=True
                )
                
                # Chuy·ªÉn v·ªÅ Numpy v√† nh√¢n v·ªõi 128 ƒë·ªÉ kh√¥i ph·ª•c ƒë·ªô b√£o h√≤a m√†u
                # (V√¨ output c·ªßa Tanh l√† -1 ƒë·∫øn 1, c√≤n m√†u Lab l√† -128 ƒë·∫øn 128)
                ab_final = ab_pred_upscaled.squeeze(0).cpu().numpy().transpose(1, 2, 0) * 128.0
                
                # --- GIAI ƒêO·∫†N 5: GH√âP ·∫¢NH ---
                # T·∫°o ·∫£nh Lab r·ªóng k√≠ch th∆∞·ªõc g·ªëc
                final_lab_image = np.zeros((orig_h, orig_w, 3))
                
                # K√™nh 0: L·∫•y t·ª´ ·∫£nh g·ªëc (ƒë·ªÉ gi·ªØ ƒë·ªô n√©t chi ti·∫øt)
                final_lab_image[:, :, 0] = L_original
                
                # K√™nh 1, 2: L·∫•y t·ª´ AI ƒë√£ ph√≥ng to (ƒë·ªÉ l·∫•y m√†u)
                final_lab_image[:, :, 1:] = ab_final
                
                # Chuy·ªÉn ng∆∞·ª£c t·ª´ Lab sang RGB ƒë·ªÉ hi·ªÉn th·ªã
                final_rgb_image = lab2rgb(final_lab_image)
                
                # --- HI·ªÇN TH·ªä K·∫æT QU·∫¢ ---
                with col2:
                    st.subheader("üé® K·∫øt qu·∫£ AI (Full HD)")
                    # clamp=True gi√∫p c·∫Øt b·ªè c√°c gi√° tr·ªã m√†u b·ªã nhi·ªÖu v∆∞·ª£t qu√° gi·ªõi h·∫°n
                    st.image(final_rgb_image, use_container_width=True, clamp=True)
                    
                st.balloons() # Ph√°o hoa ch√∫c m·ª´ng
                
            except Exception as e:
                st.error(f"C√≥ l·ªói x·∫£y ra: {e}")
                st.write("Chi ti·∫øt l·ªói:", e)